% Template for IGARSS-2018 paper; to be used with:
%          spconf.sty  - LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,epsfig}
\usepackage{graphicx}
\graphicspath{{./images/}}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{ASPHALT POTHOLE DETECTION AND VOLUME ESTIMATION USING UAV IMAGES}
%
% Single address.
% ---------------
\name{Becker Y. V. F., Marcato Jr. J.}
\address{School C-D\\
	Department C-D\\
	Address C-D}
%
% For example:
% ------------
%\address{School\\
%	Department\\
%	Address}
%
% Two addresses (uncomment and modify for two-address case).
% ----------------------------------------------------------
%\twoauthors
%  {A. Author-one, B. Author-two\sthanks{Thanks to XYZ agency for funding.}}
%	{School A-B\\
%	Department A-B\\
%	Address A-B}
%  {C. Author-three, D. Author-four\sthanks{The fourth author performed the work
%	while at ...}}
%	{School C-D\\
%	Department C-D\\
%	Address C-D}
%
\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
Transportation infrastructure needs constant maintenance. Pavement management systems requires reliable and detailed data of the current state of the roads to make effective decisions. Currently, pavement condition evaluation methods are mostly performed manually with visual inspection and interpretations in situ, which is labor intensive, time consuming and expensive. In this paper an experiment was conducted where Convolutional Neural Networks (CNNs) were applied to automatically detect potholes and UAV Photogrammetry was used to estimate their volumes. Results showed that through Structure from Motion (SfM) it is possible to estimate missing pothole volumes and the use of Ground Control Points (GCPs) doesn’t impact significantly overall measures. Using CNNs for pothole detection, it was found that the Faster-RCNN Inception ResNet model with reduced anchor box stride and image augmentation applied provides better accuracy compared to several other models tested, obtaining accuracy for this experiment of 70.4\% across five-fold cross validation.


\end{abstract}
%
\begin{keywords}
Remote Sensing, convolutional neural networks, photogrammetry.
\end{keywords}
%
\section{Introduction}
\label{sec:intro}

Considering the importance of the road network for the economy and logistic of a country, it is essential to ensure good pavement performance and safe driving conditions. Therefore, periodic road health monitoring surveys are required to collect information about the current road quality to better manage infrastructure maintenance (Salman et al., 2013). There are several issues with manual inspections. According to Salman et al. (2013), these measures suffer heavily from the associated subjectivity of human decision making. High labor cost, time consumption and dangers intrinsic to road inspections are other factors that reduce the periodicity of survey procedures (Shi et al., 2016) \cite{C2} \cite{Lamp86}.

In comparison, automated surveying systems can be fast, accurate and eliminates the subjectivity involved in human inspections (Salman et al., 2013) \cite{C2}.. Combined with the ever-increasing availability of low cost and high-quality UAVs and digital cameras in the last decade, the necessity of automation enabled research, creation and deployment of many different computer vision systems for automated surveys (Koch et al., 2015) \cite{C2}..

In this paper, two approaches for automatically detecting potholes that do not rely much on these commonly CV methods are investigated. In order to take advantage of the increasing affordability of aerial images, on account of the popularization of UAVs, a method based on photogrammetry and neural networks is proposed. Structure from Motion (SfM) is used to produce high resolution topography from randomly oriented distributed images (Colomina and Molina, 2014). The advantage is that it generates a Digital Surface Model (DSM) using only optical sensors, transforming 2D data into 3D information. This method has been extensively compared to established topology methods, such as laser scanner techniques, results are very similar in precision (Gehrke et al., 2008). Another advantage to the normally used laser alternatives, SfM using RBG cameras reduces total cost and UAV payload, which extends its flight time (Koch and Brilakis, 2011). These monetary and time advantages can lead to more frequent road inspection (Mohan and Poobal 2017) and infrastructure agencies are able to schedule repairs interventions more effectively (Tedeschi and Benedetto, 2017). The second method investigated is Convolutional Neural Networks (CNN), which is a supervised machine learning method. This type of artificial intelligence automatically learns features from the images, in contrast to the classical hand-craft computed vision algorithms that needs precise tuning of parameters and thresholds (Varadharajan et al., 2014). This method was chosen because CNNs learn features by feeding large quantity of data to the network, which can now be easily obtainable by the UAVs. As in 2D image object detection there are a lot of randomness associated with features geometry, pixel brightness and textures which are difficult to predict using classical methods, contrarily to CNNs, which are able to overcome this through convolution operations (Salman et al., 2013).

\section{Proposed Method}
\label{sec:method}

The objective of this study is to investigate methods that automatically detect the presence of a pothole and estimate its volume, given one or a sequence of aerial images of a region that contains paved roads taken by an UAV.
The proposed solution is based on two main lines: Convolutional Neural Network (CNN) for object detection and Structure from Motion (SfM) for modeling a 3D surface and detecting the potholes through depth and volumetric measurements. An experiment was conducted to test both these methods.

An UAV (DJI Phantom 4 Advanced) was used to collect images from roads that contained several potholes along its length. The chosen pavement segments had elements which were expected to be found in real case scenarios such as: trees casting shadows, parked cars covering part of the asphalt, unclear pavement boundary with the sidewalk and presence of low vegetation. Images were collected from different dates and heights: 2, 9, 25 and 50 meters above ground. 


\subsection{Convolutional Neural Networks (CNNs)}
\label{sec:pagestyle}

In this phase, the following parameters were tested to check which produces better results: UAV flying height, image resolution, data augmentation, detection algorithm and pre-trained models.
A total of 300 images were captured in different heights, light conditions and contexts. For each image, potholes were manually labeled using a free opensource software named LabelImg, (Tzutalin, 2015). After all potholes were labeled, data augmentation was applied in some data subsets using another free opensource Python library: imgaug (Alexander Jung, 2016). Data augmentation is important in machine learning experiments as it increases the amount of training data (Wang and Perez, 2017) and avoids overfitting, as the model generalizes better (Huang et al., 2017). Another research from (Ren, Zhu, and Xiao, 2018) shows the importance of image augmentation. Each image was copied 10 times and augmentations were randomly applied for each image. The operations used were translation, horizontal flip, Gaussian blur and single channel brightness amplifier.

In addition to image augmentation, some images subsets had their resolution reduced. Each image taken by the sensor is an 8.34 MB RGB jpeg file with 5472 x 3648 pixels. The images were resized to 0.5 and 0.8 of their original resolution using bilinear interpolation. As cited by (Huang et al., 2017), image resolution impacts accuracy significantly, as reducing image size by half in width and height lowers the accuracy by around 16\%.

Research in studies using CNNs in small objects helped defining which variables are more expressive when tunning pre-trained models and hyperparameters. A detection model determines how the algorithm solves object detection. It defines the methods taken from receiving the input image to returning the object class probability and location. Models vary greatly in precision and speed. As speed in inference is not a concern in this application, Faster R-CNN (Region-based Convolutional Neural Networks) was the detection algorithm chosen for this work. It is the most accurate system in comparison to SSD (Single Shot MultiBox Detector) or R-FCN (Region-based Fully Convolutional Networks), specially for small objects (Huang et al., 2017). This algorithm is composed of two networks. The Region Proposal Network (RPN) generates region proposals where objects might be found. (Zhu et al., 2018) described that Faster RCNN default parameters are not optimal for objects with reduced pixel size and obtained better results reducing anchor box stride for the Region Proposal Network.
For each different configuration dataset  80\% was used for training and 20\% for testing. As common practice (Girshick et al., 2016), transfer learning was used to modify only the last layer of an already pre-trained model. These procedures and models were not used to report final accuracy, as they were only used to find optimal parameters. After the model with highest precision was found, 5-fold cross-validation was used to report final detection performance. When given an input image, the detector returns bounding boxes around the predicted areas with the highest probability of truly being the object desired. The metric used to evaluate such prediction was Average Precision at 50\% Intersection Over Union (AP@0.50IoU). This metric is a recurrent used evaluation formula where the intersection area between the box predicted and the ground-truth box is divided by the union of both boxes (Girshick et al., 2016). If the IoU proportion is over 0.5, it is considered a correct detection. Further, precision and recall are calculated counting true positives and false positives. Summing all precisions for each recall level results in the Average Precision (AP). This was done for each of the 5 models created during the 5-fold cross validation and the reported accuracy of the model is the mean AP from all models.


\subsection{Structure from Motion (SfM)}
\label{sec:sfm}

SfM is a photogrammetry technique in which images obtained from different camera positions are processed to build a 3D point cloud. For this experiment, a 180 meters road segment was chosen to be studied. Different drone flight plans, software configuration and Ground Control Points (GCPs) were tested. The goal is to investigate best practices to estimate pothole volumes. In this experiment, images were collected from three different heights: 2, 9, and 25 meters above ground. The totality of the flights happened in the same time of the day, trying to keep illumination, shadows and objects in the scene constant for every sequence of flight. The road segment had 20 potholes and measures in situ of width, height and height (x, y and z, respectively) were annotated and georeferenced using a Realtime-kinematic (RTK) model GNSS GS15 from Leica VIVA. As the optimal number needed of GCPs was a variable to be investigated, 20 of them were placed in the area of interest. The software chosen for photogrammetric processes was Pix4Dmapper.


\section{Results}
\label{sec:results}

\subsection{Pothole detection}
\label{ssec:cnn_result}

Using the same dataset and model, applying data augmentation improves precision by 4\% compared to not applying augmentation and decreasing image resolution by 0.5. As for region proposal parameters, it was found a 2\% increase when reducing anchor box stride to 8 px compared to 16 px. Lastly, the better performing pre-trained model found for this application was the Faster-RCNN Inception ResNet v2 Atrous pre-trained on the COCO dataset.

With these configurations, 5-fold cross validation obtained a mean value of 70.4\% and 7\% standard deviation. 
 
\subsection{Pothole volumes}
\label{sssec:sfm_result}

Results from the three different heights were produced. The 2 meters height flight produced very poor results as it requires large amount of image overlap to generate a good point cloud. This height should be rejected as it consumes large amounts of time to cover big areas and has higher risk of colliding with objects and the possibility of traffic disturbance.

The 9 meters flight produced more coherent results but the lack of overlapping images and occlusion from trees caused localized errors in the point cloud.

The 25 meters height flight produced the best results as it is fast, presents no risk of collision with objects and the resolution and Ground Sample Distance (GSD) produced is still acceptable (0.71 cm). The images taken in this height, therefore, were used to analyze different numbers of GCPs and their impact on the final 3D point cloud. When no GCP was used, the 3D point cloud generated had high precision but low accuracy, as the model was correctly constructed but offset from the real location in the z axis. Another issue when not including GCPs is the increased time it takes for the point cloud processing.

Pix4D also can generate 3D point clouds using data from different flights. Results using the data from all three flights did not generate a better 3D point cloud. Even though it increases image overlap and adds more data to be processed, analysis showed worse errors than using only the 25 meters dataset. The reason is highly related to the disparity of resolution between each flight height. Also, in everyday circumstances, this procedure would not be desired as it takes longer to capture the images in multiple heights.

\section{Conclusion}
\label{sec:conclusion}

Road pavement inspections are essential for maintenance programs, but new procedures must be adopted to automate the data collection. This work investigates photogrammetry and machine learning techniques applied for potholes detection and volume estimation in pavements using UAVs as a cheap and fast way to obtain images. This work found the following: 

•	Using SfM, it is possible to estimate missing asphalt pothole volumes. This can be both done through depth analysis after generating a DSM even without allocating GCPs. The advantage over other methods (such as lasing scanner techniques) is that it uses only a common RGB sensor, which reduces operational cost and UAV payload.

•	Applying convolutional neural networks, potholes in an isolated RGB image were detected achieving 70.4\% accuracy. It was found that using the pre-trained Faster-RCNN Inception ResNet model, reducing anchor box stride during transfer learning and using image augmentation results in better accuracy.

Proven the possibility of generation of a DSM through photogrammetry and the potentiality of CNNs, further research combining RGB image and depth information or even the 3d point cloud as a feature for input in CNNs could provide more accurate models.

% Below is an example of how to insert images. Delete the ``\vspace'' line,
% uncomment the preceding line ``\centerline...'' and replace ``imageX.ps''
% with a suitable PostScript file name.
% -------------------------------------------------------------------------

\begin{figure}[htb]
\begin{minipage}[b]{1.0\linewidth}
  \centering
  \centerline{\epsfig{figure=img_sample.png,width=8.5cm}}
  \centerline{(a) Result 1}\medskip
\end{minipage}
%
\begin{minipage}[b]{.48\linewidth}
  \centering
% \centerline{\epsfig{figure=image3.ps,width=4.0cm}}
  \vspace{1.5cm}
  \centerline{(b) Results 3}\medskip
\end{minipage}
\hfill
\begin{minipage}[b]{0.48\linewidth}
  \centering
% \centerline{\epsfig{figure=image4.ps,width=4.0cm}}
  \vspace{1.5cm}
  \centerline{(c) Result 4}\medskip
\end{minipage}
%
\caption{Example of placing a figure with experimental results.}
\label{fig:res}
%
\end{figure}

\begin{figure}[!ht]
   \centering
   \begin{center}
     \includegraphics*[width=0.8\linewidth]{obj_det}
   \caption{Illustration of a user-item bipartite networks. Here users are connected with the corresponding selected items.}
   \label{fig:user-item-bipartite}
   \end{center}
\end{figure}
% To start a new column (but not a new page) and help balance the last-page
% column length use \vfill\pagebreak.
% -------------------------------------------------------------------------
\vfill
\pagebreak

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs,mend}

\end{document}
